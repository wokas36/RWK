{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import itertools\n",
    "import os,sys\n",
    "sys.path.append(os.path.realpath('../lib'))\n",
    "import numpy as np\n",
    "import ast\n",
    "from utils import split_train_test,unique_repr,create_log_dir\n",
    "from sklearn.metrics import accuracy_score\n",
    "from custom_svc import Graph_RJW_SVC_Classifier\n",
    "import time \n",
    "import utils \n",
    "import argparse\n",
    "import random\n",
    "from data_loader import load_local_data\n",
    "from IPython.core.debugger import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaMustBeDefinedError(Exception):\n",
    "    pass\n",
    "\n",
    "def explode_tuned_parameters(tuned_params):\n",
    "    tuned_parameters2=tuned_params[0]\n",
    "    varNames = sorted(tuned_parameters2)\n",
    "    combinations = [dict(zip(varNames, prod)) for prod in \n",
    "                    itertools.product(*(tuned_parameters2[varName] for varName in varNames))]\n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dict(old_dict,your_keys):\n",
    "    return { your_key: old_dict[your_key] for your_key in your_keys }\n",
    "    \n",
    "def filter_all_params(allparams,filtre_key):\n",
    "    filtered_all_params=[]\n",
    "    filtre=set(filtre_key).intersection(set(allparams[0].keys()))\n",
    "    for param in allparams:\n",
    "        filter_param=filter_dict(param,filtre)\n",
    "        if filter_param not in filtered_all_params:\n",
    "            filtered_all_params.append(filter_param)\n",
    "    return filtered_all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_rjw(X,y,tuned_parameters,dataset_name,dict_index,logging,\n",
    "               path=None,n_inner=10,n_iter=10,verbose=1,optionnal=\"\"):\n",
    "\n",
    "    \"\"\" Compute the nested cross-validation         \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array of Graph objects\n",
    "        y : array of classes of each graph\n",
    "        tuned_parameters : a list of dict \n",
    "                           Parameters to cross validate.\n",
    "        dataset_name : string \n",
    "                       name of the dataset. Used only to check the right dataset in the precalculated disances folder\n",
    "        logging : a logging object\n",
    "                  Used to write the log. Can be instantiate via utils.setup_logger\n",
    "        path : string\n",
    "               Path to the precalculated RJW distances. If not specified all distances are recalculated. \n",
    "               If specified it checks amoung all precalculated distances the ones that correspond to the cross-validated parameters\n",
    "        n_inner : integer\n",
    "                  The number of inner folds in the nested cross validation\n",
    "        n_iter : integer\n",
    "                 The number of outer folds in the nested cross validation\n",
    "        optionnal : string\n",
    "                    A optionnal name to add to the name of the log file\n",
    "        Returns\n",
    "        -------\n",
    "        Writes the results in the log file\n",
    "    \"\"\"\n",
    "\n",
    "    logging.info('############ Begin nested CV ############')\n",
    "    logging.info('Inner : '+str(n_inner))\n",
    "    logging.info('Outer : '+str(n_iter))\n",
    "    logging.info('params : '+str(tuned_parameters))\n",
    "    \n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    outer_score=[]\n",
    "    allparams=explode_tuned_parameters(tuned_parameters)\n",
    "    \n",
    "    filtre=set(Graph_RJW_SVC_Classifier().get_distances_params().keys())\n",
    "    all_params_filtered=filter_all_params(allparams,filtre)\n",
    "    index=dict_index[dataset_name]\n",
    "    \n",
    "    logging.info('Begin precomputing all distances matrices')\n",
    "    logging.info(str(len(all_params_filtered))+' matrices to fit...')\n",
    "    # Get the distances of calculates them\n",
    "    dict_of_all_distances={}\n",
    "    l=0\n",
    "    for params in all_params_filtered:\n",
    "        clf=Graph_RJW_SVC_Classifier(**params)\n",
    "        if path is None:\n",
    "            if verbose>1:\n",
    "                print('Path is None : we precalculate distances but we are not saving them')\n",
    "            clf.compute_all_distance(np.array(X),np.array(X))\n",
    "            dict_of_all_distances[unique_repr(clf.get_distances_params())]=clf.D\n",
    "        else:\n",
    "            if optionnal!=\"\":\n",
    "                name=dataset_name+optionnal\n",
    "            else:\n",
    "                name=dataset_name\n",
    "            if name+'.pkl' in os.listdir(path):\n",
    "                if verbose>1:\n",
    "                    print('Load dict')\n",
    "                d=utils.load_obj(name+'.pkl',path=path)\n",
    "            else:\n",
    "                if verbose>1:\n",
    "                    print('Create empty dict')\n",
    "                d={}\n",
    "            if unique_repr(clf.get_distances_params()) in d:\n",
    "                D=d[unique_repr(clf.get_distances_params())]\n",
    "                dict_of_all_distances[unique_repr(clf.get_distances_params())]=D/np.max(D)\n",
    "            else:\n",
    "                if verbose >1:\n",
    "                    print('Recalculate distance')\n",
    "                clf.compute_all_distance(np.array(X),np.array(X))\n",
    "                dict_of_all_distances[unique_repr(clf.get_distances_params())]=clf.D/np.max(clf.D)\n",
    "                d[unique_repr(clf.get_distances_params())]=clf.D\n",
    "                utils.save_obj(d,name,path=path)\n",
    "            logging.info('One distance done')                     \n",
    "        l+=1\n",
    "        if l%10==0 and verbose>1:\n",
    "            print('Done params : ',l)\n",
    "    logging.info('...Done')\n",
    "            \n",
    "    for i in range(n_iter):\n",
    "        k_fold=StratifiedKFold(n_splits=n_inner,random_state=i,shuffle=True)\n",
    "        G_train,y_train,idx_train,G_test,y_test,idx_test=split_train_test(list(zip(X, list(y))),ratio=0.9,seed=i,\n",
    "                                                                          index=index)    \n",
    "        acc_inner_dict={} \n",
    "        best_inner_dict={}\n",
    "        for param in allparams:\n",
    "            acc_inner_dict[repr(param)]=[]    \n",
    "            \n",
    "        for idx_subtrain, idx_valid in k_fold.split(G_train,y_train):\n",
    "            true_idx_subtrain=[idx_train[i] for i in idx_subtrain]\n",
    "            true_idx_valid=[idx_train[i] for i in idx_valid]\n",
    "\n",
    "            x_subtrain = np.array([X[i] for i in true_idx_subtrain])\n",
    "            y_subtrain = np.array([y[i] for i in true_idx_subtrain])\n",
    "            x_valid=np.array([X[i] for i in true_idx_valid])\n",
    "            y_valid=np.array([y[i] for i in true_idx_valid])\n",
    "                      \n",
    "            # For all parameter fit on subtrain and test on subtest    \n",
    "            for param in allparams:\n",
    "                # Initialise an SVM and fit.\n",
    "                clf = Graph_RJW_SVC_Classifier()\n",
    "                clf.set_params(**param)\n",
    "                                \n",
    "                # Fit on the train Kernel                                  \n",
    "                if unique_repr(clf.get_distances_params()) in dict_of_all_distances:\n",
    "                    \n",
    "                    if verbose>2:\n",
    "                        print('--------------------------------------------------------')\n",
    "                        print('Params all : ', str(unique_repr(clf.get_params())))  \n",
    "                        print('Distance pram : ', str(unique_repr(clf.get_distances_params())))\n",
    "                    \n",
    "                    D=dict_of_all_distances[unique_repr(clf.get_distances_params())]\n",
    "                    st=time.time() \n",
    "                    clf.fit(x_subtrain,y_subtrain,matrix=D[np.ix_(true_idx_subtrain,true_idx_subtrain)])\n",
    "                        \n",
    "                    # Predict and test.\n",
    "                    y_pred = clf.predict(x_valid,matrix=D[np.ix_(true_idx_valid,true_idx_subtrain)])\n",
    "                    ed=time.time()\n",
    "                    \n",
    "                    # Calculate accuracy of classification.\n",
    "                    ac_score=accuracy_score(y_valid.reshape(-1,1), y_pred.reshape(-1,1))\n",
    "                    if verbose>2:\n",
    "                        print('Done in : ',ed-st)\n",
    "                        print('--------------------------------------------------------')\n",
    "                    acc_inner_dict[repr(param)].append(ac_score)\n",
    "              \n",
    "        # Find best params in the inner\n",
    "        for key,value in acc_inner_dict.items():\n",
    "            best_inner_dict[key]=np.mean(acc_inner_dict[key])\n",
    "                \n",
    "        param_best=ast.literal_eval(max(best_inner_dict,key=best_inner_dict.get))\n",
    "        logging.info('Best params : '+str(repr(param_best)))\n",
    "\n",
    "        clf = Graph_RJW_SVC_Classifier()\n",
    "        clf.set_params(**param_best)  \n",
    "        \n",
    "        D=dict_of_all_distances[unique_repr(clf.get_distances_params())]\n",
    "                    \n",
    "        clf.fit(G_train, y_train,matrix=D[np.ix_(idx_train,idx_train)])\n",
    "        \n",
    "        y_pred = clf.predict(G_test,matrix=D[np.ix_(idx_test,idx_train)])\n",
    "        \n",
    "        ac_score_outer=accuracy_score(y_test.reshape(-1,1), y_pred.reshape(-1,1))\n",
    "        outer_score.append(ac_score_outer)\n",
    "\n",
    "        logging.info('Accuracy '+str(ac_score_outer*100))\n",
    "        logging.info('############ One outer Done ############')\n",
    "              \n",
    "    logging.info('Nested mean score '+str(np.mean(outer_score)*100))\n",
    "    logging.info('Nested std score '+str(np.std(outer_score)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log//protein_2021_10_07_19_33_10\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Nested CV for rjw')\n",
    "    parser.add_argument('-dn','--dataset_name', type=str,help='the name of the dataset',\n",
    "                        choices=['mutag','ptc','enzymes','protein','cox2','bzr','nci1',\n",
    "                                 'nci109','dd','collab','bzr_md','cox2_md'],\n",
    "                        default='mutag')\n",
    "    parser.add_argument('-d','--data_path',type=str,help='the path to the data',\n",
    "                        default='../data/')\n",
    "    parser.add_argument('-ni','--n_inner', default=10, type=int,\n",
    "                        help='the number of folds in the inner cv')\n",
    "    parser.add_argument('-no','--n_outer', default=10, type=int,\n",
    "                        help='the number of folds in the outer cv')\n",
    "    parser.add_argument('-dist','--distances_path',default='../distances/',\n",
    "                        help='the path to the precalculated distances for rjw')\n",
    "    parser.add_argument('-o','--optionnal_name',default=\"rjw\",\n",
    "                        help='optionnal name to add for the log file')\n",
    "    parser.add_argument('-r','--log_dir',default='../log/', type=str,\n",
    "                        help='the path to the directory where to write to')\n",
    "    \n",
    "    #change wl parameter for each dataset [wl=2-discrete attributes, wl=0-continuous attributes]\n",
    "    #default=2->MUTAG,PTC-MR,NCI1,NCI109,D&D AND COLLAB\n",
    "    #default=0->ENZYMES,PROTEINS,COX2,BZR,BZR-MD AND COX2-MD \n",
    "    parser.add_argument('-wl','--wl_feature',type=int,\n",
    "                        help='Use the Weisfeler Lehman features if wl>0 ',default=2) \n",
    "    \n",
    "    parser.add_argument('-at','--attributes',\n",
    "                        help='wether to use continuous attributes of the graph',type=utils.str2bool,default=True)\n",
    "    parser.add_argument('-fea','--feature_metric',type=str,\n",
    "                        choices=['euclidean','sqeuclidean','dirac','hamming_dist'],\n",
    "                        default='hamming_dist',\n",
    "                        help='the metric to use for the features')\n",
    "    parser.add_argument('-st','--structure_metric',type=str,\n",
    "                        choices=['random_walk','adjency'],help='the metric to use for the structures',\n",
    "                        default='random_walk')\n",
    "    parser.add_argument('-C','--Csvm',default=10, type=float,\n",
    "                        help='C parameter in Linear SVM. If not specified cross validated')\n",
    "    parser.add_argument('-g','--gamma',default=1, type=float,\n",
    "                        help='Gamma parameter in Gaussian SVM. If not specified cross validated')\n",
    "    parser.add_argument('-v','--verbose', default=1, type=int,help='verbose')\n",
    "    parser.add_argument('-am','--amijo',help='whether to use amijo linesearch',\n",
    "                        type=utils.str2bool,default=True)\n",
    "    \n",
    "    #change alpha for each dataset.\n",
    "    #default=[1]->MUTAG, BZR AND COX2\n",
    "    #default=[0.9]->ENZYMES AND PTC-MR\n",
    "    #default=[0.6]->PROTEINS\n",
    "    parser.add_argument('-a','--alpha',type=float, \n",
    "                        help='Alphas to cross validate. Ignored if cva is true',default=[1])\n",
    "    \n",
    "    parser.add_argument('-b','--beta',type=float, \n",
    "                        help='Betas to cross validate. Ignored if cva is true',default=[1e-4])\n",
    "    \n",
    "    parser.add_argument('-i','--index',type=list, \n",
    "                        help='indexing datasets.',default={'mutag':0,'ptc':1,'cox2':2,\n",
    "                                                           'bzr':3,'enzymes':4,'protein':5,\n",
    "                                                           'nci1':6,'nci109':7,'dd':8,'collab':9,\n",
    "                                                           'bzr_md':10,'cox2_md':11})\n",
    "    \n",
    "    parser.add_argument('-cva','--automatic_cv_alpha',\n",
    "                        help='wether to use a predifined CV grid for alpha.',\n",
    "                        type=utils.str2bool,default=False)\n",
    "\n",
    "    \n",
    "    args = parser.parse_args(args=[])\n",
    "    data_path=args.data_path\n",
    "    \n",
    "    if args.alpha==-8000 and not args.automatic_cv_alpha:\n",
    "        raise AlphaMustBeDefinedError('You must set alpha via -a')\n",
    "    \n",
    "    \n",
    "    name='rjw'+'_'+args.dataset_name+'_feature_metric_'+args.feature_metric+'_structure_metric_'+args.structure_metric\n",
    "    if args.wl_feature>0:\n",
    "        name=name+'_wl_'+str(args.wl_feature)\n",
    "    name=name+args.optionnal_name\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists(args.log_dir):\n",
    "            os.makedirs(args.log_dir)\n",
    "    except OSError:\n",
    "        raise\n",
    "\n",
    "    log_dir=create_log_dir(args)\n",
    "  \n",
    "    Clist=[args.Csvm]\n",
    "    alpha_list=args.alpha\n",
    "    beta_list=args.beta\n",
    "    gamma_list=[args.gamma]\n",
    "    \n",
    "    logger = utils.setup_logger('outer_logger', log_dir+'/'+name+'_outer.log')\n",
    "    logger.info('Let the Outer CV Begin for '+str(name))\n",
    "    logger.info('n_outer : '+str(args.n_outer))\n",
    "    logger.info('n_inner : '+str(args.n_inner)) \n",
    "      \n",
    "    X,y=load_local_data(data_path,args.dataset_name,attributes=args.attributes,wl=args.wl_feature)\n",
    "\n",
    "    tuned_parameters = [{'alpha':alpha_list,'C':Clist,'gamma':gamma_list,'beta':beta_list,\n",
    "                         'features_metric':[args.feature_metric],\n",
    "                         'method':[args.structure_metric],'wl':[args.wl_feature],'amijo':[args.amijo]}]\n",
    "    \n",
    "    nested_rjw(X,y\n",
    "        ,tuned_parameters\n",
    "        ,args.dataset_name\n",
    "        ,args.index\n",
    "        ,logger\n",
    "        ,args.distances_path\n",
    "        ,n_inner=args.n_inner\n",
    "        ,n_iter=args.n_outer\n",
    "        ,verbose=args.verbose\n",
    "        ,optionnal=str(args.optionnal_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
